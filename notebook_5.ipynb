{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning: Intro to Scikit-Learn\n",
    "\n",
    "**Advanced Astroinformatics Student Project**\n",
    "\n",
    "*N. Hernitschek, 2022*\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## Contents\n",
    "* [Recap, Questions](#first-bullet)\n",
    "* [The scikit-learn Package](#second-bullet)\n",
    "* [Basic Principles of Machine Learning ](#third-bullet)\n",
    "* [Summary](#fifth-bullet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap, Questions <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "\n",
    "Time for questions!\n",
    "\n",
    "Your **tasks until this week** were:\n",
    "\n",
    "\n",
    "Create a feature table showing the calculated features for all variable stars in the TESS sample (using the _TESS_lightcurves_outliercleaned light curves).\n",
    "\n",
    "Use this feature table to create a triangle plot showing the features first for all variable stars from one star type (e.g.: ACV). If this works, for each type create a triangle plot.\n",
    "Then, calculate the feature table also for the other versions of the light curves (_TESS_lightcurves_median_after_detrended, _TESS_lightcurves_raw). Overplot these features to each of your triangle plots. (I.e.: After this step you should have individual triangle plots for the types ACV, CEP, DCEP..., showing the calculated features for te raw, median/detrended, and outlier cleaned light curves.)\n",
    "\n",
    "What do these triangle plots tell you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The scikit-learn Package <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "\n",
    "scikit-learn is a popular Python package containing a collection of tools for machine learning.\n",
    "\n",
    "It comes with an extensive list of tutorials, see http://scikit-learn.org/stable/tutorial/basic/tutorial.html#.\n",
    "\n",
    "In general, we are interested in taking a set of samples of data and then predicting properties of unknown data. In the simplest case the data will be one dimensional, but generally we will be dealing with multi-dimensional data.\n",
    "\n",
    "As we saw in the lecture, we can break machine learning into a few distinct categories. Common to all of these is the concept of **training sets and test sets**: training data will be used to make predictions about the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation of Data in Scikit-learn\n",
    "\n",
    "Machine learning is about creating models from data: for that reason, we'll start by discussing how data can be represented in scikit-learn.\n",
    "\n",
    "Most machine learning algorithms implemented in scikit-learn expect data to be stored in a two-dimensional array or matrix. The arrays can be either numpy arrays, or in some cases `scipy.sparse matrices`. The size of the array is expected to be `[n_samples, n_features]`\n",
    "\n",
    "`n_samples`: The number of samples: each sample is an item to process (e.g. classify). A sample can be a document, a picture, a sound, a video, an astronomical object, a row in database or CSV file, or whatever you can describe with a fixed set of quantitative traits.\n",
    "    \n",
    "`n_features`: The number of features or distinct traits that can be used to describe each item in a quantitative manner. Features are generally real-valued, but may be boolean or discrete-valued in some cases.\n",
    "\n",
    "The number of features must be fixed in advance. However it can be very high dimensional (e.g. millions of features) with most of them being zeros for a given sample. This is a case where `scipy.sparse` matrices can be useful, in that they are much more memory-efficient than numpy arrays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Example: the Iris Dataset\n",
    "\n",
    "As an example of a simple dataset, we take a look at the iris data stored by scikit-learn. It is a commonly used example data set for machine learning algorithms. The data consists of measurements of three different species of irises. There are three species of iris in the dataset, which we can picture here:\n",
    "\n",
    "The data come from measurements made in Quebec by botanist Dr. Edgar Anderson and first used for Sir Ronald Fisher's 1936 [classification paper](http://rcs.chemometrics.ru/Tutorials/classification/Fisher.pdf), see [https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
    "\n",
    "\n",
    "### Loading the Iris Data with Scikit-Learn\n",
    "\n",
    "Scikit-learn has a very straightforward set of data on these iris species.  The data consist of\n",
    "the following:\n",
    "\n",
    "- **Features/attributes in the Iris dataset:**\n",
    "  1. sepal length in cm\n",
    "  2. sepal width in cm\n",
    "  3. petal length in cm\n",
    "  4. petal width in cm\n",
    "  \n",
    "  (The petal is the colorful \"leaf\" of a flower. The sepal is the green \"leaf\" at the bottom of a flower.)\n",
    "\n",
    "Scikit-learn refers to the \"labels\" as \"targets\".  So, every time you see \"target\", just think \"label\" and it will make more sense.  \n",
    "- **The target classes are:**\n",
    "  1. Iris Setosa\n",
    "  2. Iris Versicolour\n",
    "  3. Iris Virginica\n",
    "  \n",
    "``Scikit-Learn`` embeds a copy of the iris CSV file along with a helper function to load it into numpy arrays:                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
    "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
    "# result in an error if LaTeX is not installed on your system.  In that case,\n",
    "# you can set usetex to False.\n",
    "if \"setup_text_plots\" not in globals():\n",
    "    from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=10, usetex=True)\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iris` is a dictionary, so we can look at the \"keys\" of the dictionary as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "print(iris.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `target_names` were defined above\n",
    "* `data` is the `[n_samples, n_features]` data array\n",
    "* `target` is the list of labels for all of the entries in `data`\n",
    "* `DESCR` is a README file with all of the information about the data set\n",
    "* `feature_names` were defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query the database to determine the shape of the data and find that there are 150 objects with 4 measurements each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "150 4\n"
     ]
    }
   ],
   "source": [
    "print(iris.data.shape)\n",
    "n_samples, n_features = iris.data.shape\n",
    "print(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at both the first entry in `data` and the full $N\\times M$ data array. The first entry shows the values of the 4 features for the first object.\n",
    "\n",
    "Note the structure of the full data array: It is an `n_samples` array of arrays with `n_features`.  Scikit-learn requires this exact format which isn't always what you would generate naturally (particulary in the case where we have only one feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1 3.5 1.4 0.2]\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data[0])\n",
    "print(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inpect the shape of the target (labels) array, which is an `n_samples`-dimensional array, print the values of those labels, and also learn how those numerical values relate to the names of the iris species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "setosa\n"
     ]
    }
   ],
   "source": [
    "# The shape of the target (labels) array is just an n_samples X 1 array\n",
    "print(iris.target.shape)\n",
    "\n",
    "# Here we see that the labels are given numerical values\n",
    "print(iris.target)\n",
    "\n",
    "# Use target_names to translate those numerical values to names\n",
    "print(iris.target_names)\n",
    "print(iris.target_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e., $0 = $ setosa, $1 = $ versicolor, and $2 = $ virginica.\n",
    "\n",
    "This data is four-dimensional, so it's not easy to visualize. But we can make use of the `corner` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Available Test Data\n",
    "\n",
    "`scikit-learn` comes with a variety of test data:\n",
    "\n",
    "- **Packaged Data:** these small datasets are packaged with the scikit-learn installation,\n",
    "  and can be downloaded using the tools in ``sklearn.datasets.load_*``\n",
    "  \n",
    "\n",
    "- **Downloadable Data:** these larger datasets are available for download, and scikit-learn\n",
    "  includes tools which streamline this process.  These tools can be found in\n",
    "  ``sklearn.datasets.fetch_*``\n",
    "  \n",
    "  \n",
    "- **Generated Data:** there are several datasets which are generated from models based on a\n",
    "  random seed.  These are available in the ``sklearn.datasets.make_*``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Principles of Machine Learning <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "\n",
    "We can now continue with the basic principles of machine learning, and how to utilize them via Scikit-Learn.\n",
    "\n",
    "After briefly introducing scikit-learn's ***Estimator*** object, we continue with an introduction to **supervised learning**, including ***classification*** and ***regression*** problems, and **unsupervised learning**, including ***dimensionality reduction*** and ***clustering*** problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Scikit-Learn Estimator Object\n",
    "\n",
    "Every algorithm in scikit-learn generates an `Estimator` object. \n",
    "\n",
    "All the **parameters** of an estimator can be set when it is instantiated, and have suitable default values.  \n",
    "\n",
    "Let's take for example a look at all of the parameters, attributes and methods in the [LinearRegression module](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "The ''Estimator'' object is implemented as follows for linear regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "LinearRegression(normalize=True)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a LinearRegression estimator object, call it `model`\n",
    "model = LinearRegression(normalize=True)\n",
    "\n",
    "# Check an individual parameters\n",
    "print(model.normalize)\n",
    "\n",
    "# Check all of the parameters\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model instantiated, we are ready to input some data.  We make a simple test case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[ 1  3  5  7  9 11 13 15 17 19]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.arange(10)    # An array of 10 integers\n",
    "y_train = 2 * x_train + 1  # Some operation performed on that array\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to process string with tex because latex could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/texmanager.py:233\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[0;34m(self, command, tex, cwd)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 233\u001b[0m     report \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mcheck_output(\n\u001b[1;32m    234\u001b[0m         command, cwd\u001b[39m=\u001b[39;49mcwd \u001b[39mif\u001b[39;49;00m cwd \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtexcache,\n\u001b[1;32m    235\u001b[0m         stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mSTDOUT)\n\u001b[1;32m    236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/subprocess.py:420\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[0;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39;49mpopenargs, stdout\u001b[39m=\u001b[39;49mPIPE, timeout\u001b[39m=\u001b[39;49mtimeout, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    421\u001b[0m            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/subprocess.py:501\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m--> 501\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    502\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/subprocess.py:966\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    964\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 966\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    967\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    968\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    969\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    970\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    971\u001b[0m                         errread, errwrite,\n\u001b[1;32m    972\u001b[0m                         restore_signals,\n\u001b[1;32m    973\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    974\u001b[0m                         start_new_session)\n\u001b[1;32m    975\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    976\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/subprocess.py:1842\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1841\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1842\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1843\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'latex'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    340\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    341\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/pylabtools.py:168\u001b[0m, in \u001b[0;36mretina_figure\u001b[0;34m(fig, base64, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mretina_figure\u001b[39m(fig, base64\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    160\u001b[0m     \u001b[39m\"\"\"format a figure as a pixel-doubled (retina) PNG\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[39m    If `base64` is True, return base64-encoded str instead of raw bytes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m        base64 argument\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     pngdata \u001b[39m=\u001b[39m print_figure(fig, fmt\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mretina\u001b[39;49m\u001b[39m\"\u001b[39;49m, base64\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    169\u001b[0m     \u001b[39m# Make sure that retina_figure acts just like print_figure and returns\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[39m# None when the figure is empty.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mif\u001b[39;00m pngdata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 151\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    152\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/backend_bases.py:2295\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2289\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[1;32m   2290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m   2291\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   2292\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m   2293\u001b[0m     )\n\u001b[1;32m   2294\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2295\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m   2297\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2298\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 73\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     75\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/figure.py:2810\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2807\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 2810\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   2811\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   2813\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   2814\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/axes/_base.py:3082\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   3080\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> 3082\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3083\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3085\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/axis.py:1159\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m renderer\u001b[39m.\u001b[39mopen_group(\u001b[39m__name__\u001b[39m, gid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gid())\n\u001b[1;32m   1158\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_ticks()\n\u001b[0;32m-> 1159\u001b[0m ticklabelBoxes, ticklabelBoxes2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1160\u001b[0m                                                         renderer)\n\u001b[1;32m   1162\u001b[0m \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks_to_draw:\n\u001b[1;32m   1163\u001b[0m     tick\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/axis.py:1085\u001b[0m, in \u001b[0;36mAxis._get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_tick_bboxes\u001b[39m(\u001b[39mself\u001b[39m, ticks, renderer):\n\u001b[1;32m   1084\u001b[0m     \u001b[39m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1086\u001b[0m              \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()],\n\u001b[1;32m   1087\u001b[0m             [tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1088\u001b[0m              \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/axis.py:1085\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_tick_bboxes\u001b[39m(\u001b[39mself\u001b[39m, ticks, renderer):\n\u001b[1;32m   1084\u001b[0m     \u001b[39m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39;49mlabel1\u001b[39m.\u001b[39;49mget_window_extent(renderer)\n\u001b[1;32m   1086\u001b[0m              \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()],\n\u001b[1;32m   1087\u001b[0m             [tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1088\u001b[0m              \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/text.py:910\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot get window extent w/o renderer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[0;32m--> 910\u001b[0m     bbox, info, descent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_layout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_renderer)\n\u001b[1;32m    911\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_unitless_position()\n\u001b[1;32m    912\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_transform()\u001b[39m.\u001b[39mtransform((x, y))\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/text.py:309\u001b[0m, in \u001b[0;36mText._get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    306\u001b[0m ys \u001b[39m=\u001b[39m []\n\u001b[1;32m    308\u001b[0m \u001b[39m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m _, lp_h, lp_d \u001b[39m=\u001b[39m renderer\u001b[39m.\u001b[39;49mget_text_width_height_descent(\n\u001b[1;32m    310\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mlp\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fontproperties,\n\u001b[1;32m    311\u001b[0m     ismath\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTeX\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_usetex() \u001b[39melse\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    312\u001b[0m min_dy \u001b[39m=\u001b[39m (lp_h \u001b[39m-\u001b[39m lp_d) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_linespacing\n\u001b[1;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m i, line \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(lines):\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:259\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    257\u001b[0m     texmanager \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_texmanager()\n\u001b[1;32m    258\u001b[0m     fontsize \u001b[39m=\u001b[39m prop\u001b[39m.\u001b[39mget_size_in_points()\n\u001b[0;32m--> 259\u001b[0m     w, h, d \u001b[39m=\u001b[39m texmanager\u001b[39m.\u001b[39;49mget_text_width_height_descent(\n\u001b[1;32m    260\u001b[0m         s, fontsize, renderer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    261\u001b[0m     \u001b[39mreturn\u001b[39;00m w, h, d\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m ismath:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/texmanager.py:335\u001b[0m, in \u001b[0;36mTexManager.get_text_width_height_descent\u001b[0;34m(self, tex, fontsize, renderer)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m tex\u001b[39m.\u001b[39mstrip() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m--> 335\u001b[0m dvifile \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_dvi(tex, fontsize)\n\u001b[1;32m    336\u001b[0m dpi_fraction \u001b[39m=\u001b[39m renderer\u001b[39m.\u001b[39mpoints_to_pixels(\u001b[39m1.\u001b[39m) \u001b[39mif\u001b[39;00m renderer \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    337\u001b[0m \u001b[39mwith\u001b[39;00m dviread\u001b[39m.\u001b[39mDvi(dvifile, \u001b[39m72\u001b[39m \u001b[39m*\u001b[39m dpi_fraction) \u001b[39mas\u001b[39;00m dvi:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/texmanager.py:271\u001b[0m, in \u001b[0;36mTexManager.make_dvi\u001b[0;34m(self, tex, fontsize)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[39m# Generate the dvi in a temporary directory to avoid race\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[39m# conditions e.g. if multiple processes try to process the same tex\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[39m# string at the same time.  Having tmpdir be a subdirectory of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[39m# the absolute path may contain characters (e.g. ~) that TeX does\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[39m# not support.)\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     \u001b[39mwith\u001b[39;00m TemporaryDirectory(\u001b[39mdir\u001b[39m\u001b[39m=\u001b[39mPath(dvifile)\u001b[39m.\u001b[39mparent) \u001b[39mas\u001b[39;00m tmpdir:\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_checked_subprocess(\n\u001b[1;32m    272\u001b[0m             [\u001b[39m\"\u001b[39;49m\u001b[39mlatex\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m-interaction=nonstopmode\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m--halt-on-error\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    273\u001b[0m              \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../\u001b[39;49m\u001b[39m{\u001b[39;49;00mtexfile\u001b[39m.\u001b[39;49mname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m], tex, cwd\u001b[39m=\u001b[39;49mtmpdir)\n\u001b[1;32m    274\u001b[0m         (Path(tmpdir) \u001b[39m/\u001b[39m Path(dvifile)\u001b[39m.\u001b[39mname)\u001b[39m.\u001b[39mreplace(dvifile)\n\u001b[1;32m    275\u001b[0m \u001b[39mreturn\u001b[39;00m dvifile\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/texmanager.py:237\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[0;34m(self, command, tex, cwd)\u001b[0m\n\u001b[1;32m    233\u001b[0m     report \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mcheck_output(\n\u001b[1;32m    234\u001b[0m         command, cwd\u001b[39m=\u001b[39mcwd \u001b[39mif\u001b[39;00m cwd \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtexcache,\n\u001b[1;32m    235\u001b[0m         stderr\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mSTDOUT)\n\u001b[1;32m    236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    238\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mFailed to process string with tex because \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m could not be \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    239\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfound\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(command[\u001b[39m0\u001b[39m])) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m{prog}\u001b[39;00m\u001b[39m was not able to process the following string:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    243\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m{tex!r}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m             tex\u001b[39m=\u001b[39mtex\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39municode_escape\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m    248\u001b[0m             exc\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to process string with tex because latex could not be found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, y_train, 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd like to `fit` that data to determine the model parameters that we would need to `predict` the $y$ values of any new measurement of $x$.  \n",
    "\n",
    "The general code syntax for this sort of thing might be\n",
    "\n",
    "```\n",
    "lsqfit x_train y_train x_test y_pred\n",
    "```\n",
    "\n",
    "Scikit-Learn breaks this into two steps:\n",
    "1. **fitting**\n",
    "2. **predicting**\n",
    "    \n",
    "where the syntax of the fit looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "[ 1  3  5  7  9 11 13 15 17 19]\n"
     ]
    }
   ],
   "source": [
    "# The input data for sklearn must be 2D: (samples == N x features == 1)\n",
    "print(x_train)\n",
    "\n",
    "# All of these give the same result.  I'll adopt the convention from the last one.\n",
    "print(x_train.reshape(-1,1))\n",
    "print(x_train[:, np.newaxis])\n",
    "print(np.atleast_2d(x_train).T)\n",
    "print(x_train[:, None])\n",
    "\n",
    "X = x_train[:, None]\n",
    "y = y_train\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(normalize=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can fit the model on our data\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the fit parameters, which are indicated by an underscore at the end\n",
    "print(model.coef_)\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model found a line with a slope 2 and intercept 1 (as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Supervised Learning <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "\n",
    "\n",
    "In **Supervised Learning**, we have a dataset consisting of both ***features*** and ***labels***. The task is to construct an estimator that is able to predict the label of an object given the set of features. A relatively simple example is predicting the species of iris given a set of measurements of its flower.\n",
    "\n",
    "Some more complicated examples are:\n",
    "\n",
    "- given a multicolor image of an object through a telescope, determine\n",
    "  whether that object is a star, a quasar, or a galaxy.\n",
    "  \n",
    "  \n",
    "- given a time series and its extracted features, determine which kind of variable star the object is.\n",
    "\n",
    "The commonality of these tasks is that there are one or more unknown properties of an object to be determined from other observed quantities.\n",
    "\n",
    "Supervised learning is further broken down into two categories, \n",
    "1. **classification** (discrete labels)\n",
    "2. **regression** (continuous labels)\n",
    "\n",
    "For example, the task of determining whether an object is a star, a galaxy, an asteroid or a quasar is a classification problem: the label is from three distinct categories. Estimating the age of an object based on such observations however would be a regression problem, because the label (age) is a continuous quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Example\n",
    "\n",
    "[K nearest neighbors (kNN)](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) is one of the simplest learning strategies: given a new, unknown observation, look up in your reference database which ones have the closest features and assign the predominant class.\n",
    "\n",
    "We it out on our iris classification problem.  First see if you can do a kNN fit on the iris data using the 5 nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# create the model\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the model\n",
    "knn.fit(X, y)\n",
    "\n",
    "# What kind of iris has 3cm x 5cm sepal and 4cm x 2cm petal?\n",
    "# call the \"predict\" method:\n",
    "result = knn.predict([[3, 5, 4, 2],])\n",
    "\n",
    "print(iris.target_names[result])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do probabilistic predictions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.8, 0.2]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba([[3, 5, 4, 2],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.180808080808081, 8.019191919191918, 1.8868686868686868, 4.513131313131313)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to process string with tex because latex could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/texmanager.py:233\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[0;34m(self, command, tex, cwd)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 233\u001b[0m     report \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mcheck_output(\n\u001b[1;32m    234\u001b[0m         command, cwd\u001b[39m=\u001b[39;49mcwd \u001b[39mif\u001b[39;49;00m cwd \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtexcache,\n\u001b[1;32m    235\u001b[0m         stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mSTDOUT)\n\u001b[1;32m    236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/subprocess.py:420\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[0;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39;49mpopenargs, stdout\u001b[39m=\u001b[39;49mPIPE, timeout\u001b[39m=\u001b[39;49mtimeout, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    421\u001b[0m            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/subprocess.py:501\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m--> 501\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    502\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/subprocess.py:966\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    964\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 966\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    967\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    968\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    969\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    970\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    971\u001b[0m                         errread, errwrite,\n\u001b[1;32m    972\u001b[0m                         restore_signals,\n\u001b[1;32m    973\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    974\u001b[0m                         start_new_session)\n\u001b[1;32m    975\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    976\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/subprocess.py:1842\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1841\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1842\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1843\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'latex'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    340\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    341\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/pylabtools.py:168\u001b[0m, in \u001b[0;36mretina_figure\u001b[0;34m(fig, base64, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mretina_figure\u001b[39m(fig, base64\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    160\u001b[0m     \u001b[39m\"\"\"format a figure as a pixel-doubled (retina) PNG\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[39m    If `base64` is True, return base64-encoded str instead of raw bytes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m        base64 argument\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     pngdata \u001b[39m=\u001b[39m print_figure(fig, fmt\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mretina\u001b[39;49m\u001b[39m\"\u001b[39;49m, base64\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    169\u001b[0m     \u001b[39m# Make sure that retina_figure acts just like print_figure and returns\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[39m# None when the figure is empty.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mif\u001b[39;00m pngdata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/IPython/core/pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 151\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    152\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/backend_bases.py:2295\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2289\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[1;32m   2290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m   2291\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   2292\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m   2293\u001b[0m     )\n\u001b[1;32m   2294\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2295\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m   2297\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2298\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 73\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     75\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/figure.py:2810\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2807\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 2810\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   2811\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   2813\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   2814\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/axes/_base.py:3082\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   3080\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> 3082\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3083\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3085\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     51\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/axis.py:1159\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m renderer\u001b[39m.\u001b[39mopen_group(\u001b[39m__name__\u001b[39m, gid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gid())\n\u001b[1;32m   1158\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_ticks()\n\u001b[0;32m-> 1159\u001b[0m ticklabelBoxes, ticklabelBoxes2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1160\u001b[0m                                                         renderer)\n\u001b[1;32m   1162\u001b[0m \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks_to_draw:\n\u001b[1;32m   1163\u001b[0m     tick\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/axis.py:1085\u001b[0m, in \u001b[0;36mAxis._get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_tick_bboxes\u001b[39m(\u001b[39mself\u001b[39m, ticks, renderer):\n\u001b[1;32m   1084\u001b[0m     \u001b[39m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1086\u001b[0m              \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()],\n\u001b[1;32m   1087\u001b[0m             [tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1088\u001b[0m              \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/axis.py:1085\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_tick_bboxes\u001b[39m(\u001b[39mself\u001b[39m, ticks, renderer):\n\u001b[1;32m   1084\u001b[0m     \u001b[39m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39;49mlabel1\u001b[39m.\u001b[39;49mget_window_extent(renderer)\n\u001b[1;32m   1086\u001b[0m              \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()],\n\u001b[1;32m   1087\u001b[0m             [tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1088\u001b[0m              \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/text.py:910\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot get window extent w/o renderer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[0;32m--> 910\u001b[0m     bbox, info, descent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_layout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_renderer)\n\u001b[1;32m    911\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_unitless_position()\n\u001b[1;32m    912\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_transform()\u001b[39m.\u001b[39mtransform((x, y))\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/text.py:309\u001b[0m, in \u001b[0;36mText._get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    306\u001b[0m ys \u001b[39m=\u001b[39m []\n\u001b[1;32m    308\u001b[0m \u001b[39m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m _, lp_h, lp_d \u001b[39m=\u001b[39m renderer\u001b[39m.\u001b[39;49mget_text_width_height_descent(\n\u001b[1;32m    310\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mlp\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fontproperties,\n\u001b[1;32m    311\u001b[0m     ismath\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTeX\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_usetex() \u001b[39melse\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    312\u001b[0m min_dy \u001b[39m=\u001b[39m (lp_h \u001b[39m-\u001b[39m lp_d) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_linespacing\n\u001b[1;32m    314\u001b[0m \u001b[39mfor\u001b[39;00m i, line \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(lines):\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:259\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    257\u001b[0m     texmanager \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_texmanager()\n\u001b[1;32m    258\u001b[0m     fontsize \u001b[39m=\u001b[39m prop\u001b[39m.\u001b[39mget_size_in_points()\n\u001b[0;32m--> 259\u001b[0m     w, h, d \u001b[39m=\u001b[39m texmanager\u001b[39m.\u001b[39;49mget_text_width_height_descent(\n\u001b[1;32m    260\u001b[0m         s, fontsize, renderer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    261\u001b[0m     \u001b[39mreturn\u001b[39;00m w, h, d\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m ismath:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/texmanager.py:335\u001b[0m, in \u001b[0;36mTexManager.get_text_width_height_descent\u001b[0;34m(self, tex, fontsize, renderer)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m tex\u001b[39m.\u001b[39mstrip() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m--> 335\u001b[0m dvifile \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_dvi(tex, fontsize)\n\u001b[1;32m    336\u001b[0m dpi_fraction \u001b[39m=\u001b[39m renderer\u001b[39m.\u001b[39mpoints_to_pixels(\u001b[39m1.\u001b[39m) \u001b[39mif\u001b[39;00m renderer \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    337\u001b[0m \u001b[39mwith\u001b[39;00m dviread\u001b[39m.\u001b[39mDvi(dvifile, \u001b[39m72\u001b[39m \u001b[39m*\u001b[39m dpi_fraction) \u001b[39mas\u001b[39;00m dvi:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/texmanager.py:271\u001b[0m, in \u001b[0;36mTexManager.make_dvi\u001b[0;34m(self, tex, fontsize)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[39m# Generate the dvi in a temporary directory to avoid race\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[39m# conditions e.g. if multiple processes try to process the same tex\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[39m# string at the same time.  Having tmpdir be a subdirectory of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[39m# the absolute path may contain characters (e.g. ~) that TeX does\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[39m# not support.)\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     \u001b[39mwith\u001b[39;00m TemporaryDirectory(\u001b[39mdir\u001b[39m\u001b[39m=\u001b[39mPath(dvifile)\u001b[39m.\u001b[39mparent) \u001b[39mas\u001b[39;00m tmpdir:\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_checked_subprocess(\n\u001b[1;32m    272\u001b[0m             [\u001b[39m\"\u001b[39;49m\u001b[39mlatex\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m-interaction=nonstopmode\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m--halt-on-error\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    273\u001b[0m              \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../\u001b[39;49m\u001b[39m{\u001b[39;49;00mtexfile\u001b[39m.\u001b[39;49mname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m], tex, cwd\u001b[39m=\u001b[39;49mtmpdir)\n\u001b[1;32m    274\u001b[0m         (Path(tmpdir) \u001b[39m/\u001b[39m Path(dvifile)\u001b[39m.\u001b[39mname)\u001b[39m.\u001b[39mreplace(dvifile)\n\u001b[1;32m    275\u001b[0m \u001b[39mreturn\u001b[39;00m dvifile\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/matplotlib/texmanager.py:237\u001b[0m, in \u001b[0;36mTexManager._run_checked_subprocess\u001b[0;34m(self, command, tex, cwd)\u001b[0m\n\u001b[1;32m    233\u001b[0m     report \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mcheck_output(\n\u001b[1;32m    234\u001b[0m         command, cwd\u001b[39m=\u001b[39mcwd \u001b[39mif\u001b[39;00m cwd \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtexcache,\n\u001b[1;32m    235\u001b[0m         stderr\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mSTDOUT)\n\u001b[1;32m    236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    238\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mFailed to process string with tex because \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m could not be \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    239\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfound\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(command[\u001b[39m0\u001b[39m])) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m{prog}\u001b[39;00m\u001b[39m was not able to process the following string:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    243\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m{tex!r}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m             tex\u001b[39m=\u001b[39mtex\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39municode_escape\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m    248\u001b[0m             exc\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to process string with tex because latex could not be found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Create color maps for 3-class classification problem, as with iris\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features. We could\n",
    "                        # avoid this ugly slicing by using a two-dim dataset\n",
    "y = iris.target\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X, y)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "pl.figure()\n",
    "pl.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "pl.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "pl.xlabel('sepal length (cm)')\n",
    "pl.ylabel('sepal width (cm)')\n",
    "pl.axis('tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "\n",
    "An important aspect of ML is **model validation**:\n",
    "*determining how well your model will generalize from the training data to future unlabeled data.* \n",
    "\n",
    "Let's look at an example using the ***nearest neighbor classifier***. This is a very simple classifier. It stores all training data, and for any unknown quantity, simply returns the label of the closest training point.\n",
    "\n",
    "With the iris data, it very easily returns the correct prediction for each of the input points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X, y = iris.data, iris.target\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "print('Element-wise check: ' + str(y==y_pred))\n",
    "print('All-at-once check: ' + str(np.all(y == y_pred))) # To check all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more useful way to look at the results is to view the **confusion matrix**, or the matrix showing the frequency of inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read each element of the matrix as \"*the number of observations known to be in row-$i$ and predicted to be in column-$j$*\".\n",
    "\n",
    "For each of the three classes, all 50 training samples are correctly identified. But this **does not mean that our model is perfect!** In particular, such a model generalizes extremely poorly to new data. We can simulate this by splitting our data into a ***training set*** and a ***test set***. Scikit-learn contains some convenient routines to do this: here we will apply [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "ypred = clf.predict(Xtest)\n",
    "print(confusion_matrix(ytest, ypred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paints a better picture of the true performance of our classifier: apparently there is some confusion between the second and third species, which we might anticipate given what we've seen of the data above.\n",
    "\n",
    "This is why it's **extremely important** to use a train/test split like 10-fold cross-validation when evaluating machine-learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a nicer confusion matrix\n",
    "\n",
    "Especially for larger data sets with more features, it can be very helpful to make a plot of the confusion matrix, containing color-coded cells as well as labels.\n",
    "By using the code provided in the following cell, you can make such plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def to_density(cf):\n",
    "  '''\n",
    "  This function will take in a confusion matrix cf and return the relative 'density' of every element in each row.\n",
    "  ---------\n",
    "  cf: Confusion matrix to be passed in\n",
    "  '''\n",
    "  density = []\n",
    "  n, k = cf.shape\n",
    "  for i in range(n):\n",
    "    density_row = []\n",
    "    for j in range(k):\n",
    "      total_stars = sum(cf[i])\n",
    "      density_row.append(cf[i][j]/total_stars)\n",
    "    density.append(density_row)\n",
    "  return np.array(density)\n",
    "\n",
    "\n",
    "def make_confusion_matrix(cf_,\n",
    "                          xlabel, ylabel,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None,\n",
    "                          ):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf_:            Confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "    cf = to_density(cf_)\n",
    "    \n",
    "    # Generate the labels for the matrix elements:\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.2f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}\".strip() for v1, v2 in zip(group_labels,group_counts)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # Set figure paramaters:\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # Make the heatmap:\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel(xlabel)\n",
    "        plt.xlabel(ylabel)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a confusion matrix plot for k-means clustering:\n",
    "\n",
    "make_confusion_matrix(confusion_matrix(ytest, ypred), xlabel='cluster', ylabel='type', categories=iris.target_names, count=True, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your tasks until next week:**\n",
    "\n",
    "Using the TESS features you have calculated, try to code k-means clustering in the same way as shown here for the `iris` data set.\n",
    "\n",
    "Carry out 10-fold verification, and make a confusion matrix.\n",
    "\n",
    "Try to interpret your results.\n",
    "How do your results differ from the a) _TESS_lightcurves_median_after_detrended, b) _TESS_lightcurves_outliercleaned, c) _TESS_lightcurves_raw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "\n",
    "At this point, all of you should have:\n",
    "* seen how `scikit-learn` works in general\n",
    "* seen some complete examples of machine learning\n",
    "* seen ways on how to verify machine learning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c6734141a65471e905a2515875e1c91e41dfb1a2f4fe6828aa977f658d2585b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
